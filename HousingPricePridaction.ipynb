{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e518eb97-25f5-4e2b-953f-09ea63bc3d79",
   "metadata": {},
   "source": [
    "# *Problem Statement*\n",
    "A House Price Prediction Model in machine learning is a predictive model that estimates the market price of a property (house) based on various input features or attributes of the property. These features typically include both structural and environmental factors that could affect a property's value, such as its size, location, number of bedrooms, number of bathrooms, age of the house, proximity to amenities, neighborhood crime rate, and other socio-economic indicators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94e2eaf-b768-48ee-80e6-5f41309586c8",
   "metadata": {},
   "source": [
    "# START <BR>\n",
    "**ProjectTeamID:- PTID-CDS-NOV-24-2192**<br>\n",
    "**ProjectID:- PRCP-1020-HousePricePred**<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "357e745c-b6b6-45e3-b17e-029931544758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Markdown, display\n",
    "import seaborn as sns\n",
    "from ydata_profiling import ProfileReport\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def set_on():\n",
    "    pd.set_option('display.max_rows', None)  \n",
    "    pd.set_option('display.max_columns', None)  \n",
    "\n",
    "def set_off():\n",
    "    pd.reset_option('display.max_rows')  \n",
    "    pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6d3cbed-d141-4c77-9bfc-ddadf6e2c7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housePrice=pd.read_csv(\"Data/HousePrice.csv\")\n",
    "\n",
    "df_housePrice.drop(columns=\"Id\",axis=1,inplace=True)\n",
    "tg='SalePrice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d887739-3386-4be1-a67e-a8d6a3a394e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 80)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_housePrice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72a850c9-e13d-4f2b-9a59-4535ea7702d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 80 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   MSSubClass     1460 non-null   int64  \n",
      " 1   MSZoning       1460 non-null   object \n",
      " 2   LotFrontage    1201 non-null   float64\n",
      " 3   LotArea        1460 non-null   int64  \n",
      " 4   Street         1460 non-null   object \n",
      " 5   Alley          91 non-null     object \n",
      " 6   LotShape       1460 non-null   object \n",
      " 7   LandContour    1460 non-null   object \n",
      " 8   Utilities      1460 non-null   object \n",
      " 9   LotConfig      1460 non-null   object \n",
      " 10  LandSlope      1460 non-null   object \n",
      " 11  Neighborhood   1460 non-null   object \n",
      " 12  Condition1     1460 non-null   object \n",
      " 13  Condition2     1460 non-null   object \n",
      " 14  BldgType       1460 non-null   object \n",
      " 15  HouseStyle     1460 non-null   object \n",
      " 16  OverallQual    1460 non-null   int64  \n",
      " 17  OverallCond    1460 non-null   int64  \n",
      " 18  YearBuilt      1460 non-null   int64  \n",
      " 19  YearRemodAdd   1460 non-null   int64  \n",
      " 20  RoofStyle      1460 non-null   object \n",
      " 21  RoofMatl       1460 non-null   object \n",
      " 22  Exterior1st    1460 non-null   object \n",
      " 23  Exterior2nd    1460 non-null   object \n",
      " 24  MasVnrType     588 non-null    object \n",
      " 25  MasVnrArea     1452 non-null   float64\n",
      " 26  ExterQual      1460 non-null   object \n",
      " 27  ExterCond      1460 non-null   object \n",
      " 28  Foundation     1460 non-null   object \n",
      " 29  BsmtQual       1423 non-null   object \n",
      " 30  BsmtCond       1423 non-null   object \n",
      " 31  BsmtExposure   1422 non-null   object \n",
      " 32  BsmtFinType1   1423 non-null   object \n",
      " 33  BsmtFinSF1     1460 non-null   int64  \n",
      " 34  BsmtFinType2   1422 non-null   object \n",
      " 35  BsmtFinSF2     1460 non-null   int64  \n",
      " 36  BsmtUnfSF      1460 non-null   int64  \n",
      " 37  TotalBsmtSF    1460 non-null   int64  \n",
      " 38  Heating        1460 non-null   object \n",
      " 39  HeatingQC      1460 non-null   object \n",
      " 40  CentralAir     1460 non-null   object \n",
      " 41  Electrical     1459 non-null   object \n",
      " 42  1stFlrSF       1460 non-null   int64  \n",
      " 43  2ndFlrSF       1460 non-null   int64  \n",
      " 44  LowQualFinSF   1460 non-null   int64  \n",
      " 45  GrLivArea      1460 non-null   int64  \n",
      " 46  BsmtFullBath   1460 non-null   int64  \n",
      " 47  BsmtHalfBath   1460 non-null   int64  \n",
      " 48  FullBath       1460 non-null   int64  \n",
      " 49  HalfBath       1460 non-null   int64  \n",
      " 50  BedroomAbvGr   1460 non-null   int64  \n",
      " 51  KitchenAbvGr   1460 non-null   int64  \n",
      " 52  KitchenQual    1460 non-null   object \n",
      " 53  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 54  Functional     1460 non-null   object \n",
      " 55  Fireplaces     1460 non-null   int64  \n",
      " 56  FireplaceQu    770 non-null    object \n",
      " 57  GarageType     1379 non-null   object \n",
      " 58  GarageYrBlt    1379 non-null   float64\n",
      " 59  GarageFinish   1379 non-null   object \n",
      " 60  GarageCars     1460 non-null   int64  \n",
      " 61  GarageArea     1460 non-null   int64  \n",
      " 62  GarageQual     1379 non-null   object \n",
      " 63  GarageCond     1379 non-null   object \n",
      " 64  PavedDrive     1460 non-null   object \n",
      " 65  WoodDeckSF     1460 non-null   int64  \n",
      " 66  OpenPorchSF    1460 non-null   int64  \n",
      " 67  EnclosedPorch  1460 non-null   int64  \n",
      " 68  3SsnPorch      1460 non-null   int64  \n",
      " 69  ScreenPorch    1460 non-null   int64  \n",
      " 70  PoolArea       1460 non-null   int64  \n",
      " 71  PoolQC         7 non-null      object \n",
      " 72  Fence          281 non-null    object \n",
      " 73  MiscFeature    54 non-null     object \n",
      " 74  MiscVal        1460 non-null   int64  \n",
      " 75  MoSold         1460 non-null   int64  \n",
      " 76  YrSold         1460 non-null   int64  \n",
      " 77  SaleType       1460 non-null   object \n",
      " 78  SaleCondition  1460 non-null   object \n",
      " 79  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(34), object(43)\n",
      "memory usage: 912.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_housePrice.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e04bd1-8b65-43c7-b1a0-1f950784b561",
   "metadata": {},
   "source": [
    "# Identifying the columns with null values and addressing them appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4e0975a-b976-413d-b7f4-e19dfd8a606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housePrice.isnull().sum()\n",
    "null_col=df_housePrice.columns[df_housePrice.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6665f89b-0fdf-48b7-9ed7-c4d5215c194d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<4> Columns are Hving more than 70% of missing Values\n",
      "<4> Columns are Hving more than 60% of missing Values\n",
      "<5> Columns are Hving more than 50% of missing Values\n",
      "<6> Columns are Hving more than 40% of missing Values\n",
      "<6> Columns are Hving more than 30% of missing Values\n",
      "<6> Columns are Hving more than 20% of missing Values\n"
     ]
    }
   ],
   "source": [
    "def count_nullper(prg):\n",
    "    high_nullcol=[]\n",
    "    for i in df_housePrice[null_col]:\n",
    "        if i==\"SalePrice\":\n",
    "            continue\n",
    "        if(df_housePrice[i].isnull().sum()/len(df_housePrice) * 100)> prg:\n",
    "            high_nullcol.append(i)\n",
    "    return len(high_nullcol)\n",
    "\n",
    "for i in range(70,10,-10):\n",
    "    print(f'<{count_nullper(i)}> Columns are Hving more than {i}% of missing Values')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aef6eda-bc58-4a46-94fe-0ae4fc1aba83",
   "metadata": {},
   "source": [
    "## From hear we can select the lebel of percentage to decide to drop Null valued coloumn \n",
    "\n",
    "### We can compromise <5> Columns where missing values count is more than 50% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a41c79a-cbe8-4075-9ba1-c56beb081c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# These are the 5 Columns that we droped Now, \n",
       " # RIP ü™¶üíêüíê\n",
       "['Alley', 'MasVnrType', 'PoolQC', 'Fence', 'MiscFeature']"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_droped=[]\n",
    "prg=50\n",
    "for i in df_housePrice[null_col]:\n",
    "    if(df_housePrice[i].isnull().sum()/len(df_housePrice) * 100)> prg:\n",
    "        df_housePrice.drop(columns=i,axis=1,inplace=True)\n",
    "        list_of_droped.append(i)\n",
    "Markdown(f\"# These are the {len(list_of_droped)} Columns that we droped Now, \\n # RIP ü™¶üíêüíê\\n{list_of_droped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a279ea6-bef0-4daa-9316-93a871c783bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "del list_of_droped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e29b41ad-1b75-482c-b3ca-4459e3b899cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 75)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_housePrice.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14397ea4-1653-4a25-bc85-53447c360926",
   "metadata": {},
   "source": [
    "## Exteract Numerical and Categorical Null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1bcafce-b08d-4a11-bbad-bd770cc3acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_col=df_housePrice.columns[df_housePrice.isnull().any()]\n",
    "\n",
    "null_Numerical=df_housePrice[null_col].select_dtypes(include='number')\n",
    "null_Categorical=df_housePrice[null_col].select_dtypes(include='O')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c313f418-42c3-401e-96b7-cdaee4888066",
   "metadata": {},
   "source": [
    "## What are the unique values and there mode of each category Column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f1d6c7-1e22-45b0-9071-c20c8cdaa431",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in null_Categorical.columns:\n",
    "    modev=df_housePrice[i].mode()[0]\n",
    "    print(f\"The unique values for {i} are:- \\n {null_Categorical[i].dropna().unique()} \\n: mode= {modev} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba2f76f-26e8-4c8b-b4dc-f1c3b6585b6b",
   "metadata": {},
   "source": [
    "## Missing values in categorical columns are addressed by imputing with there respective mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1185908f-642e-4732-bf02-1645e3243358",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in null_Categorical.columns:\n",
    "    modev=df_housePrice[i].mode()[0]\n",
    "    df_housePrice[i].fillna(modev, inplace=True)\n",
    "    print(f'Null entries in {i} filled with it\\'s mode: \"{modev}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fe83dc-3394-48cf-b6a4-2e4e551bb6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housePrice[null_Categorical.columns].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eae7db-fc2c-4034-bba6-b944564f4d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "del null_Categorical\n",
    "del null_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85026704-2f8b-4a17-9fbf-29cd27b5c65d",
   "metadata": {},
   "source": [
    "## Handling numerical null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c806fd36-0034-48fd-86a3-9109447d9678",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_Numerical.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334e745f-59f2-4542-a414-55fd0901fafa",
   "metadata": {},
   "source": [
    "## The values in the \"GaragYrBlt\" column exhibit significant standard variation and temporal variance. Therefore, the null values will be populated with the preceding valid entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5499ab-b129-4144-a625-5395b3afc719",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housePrice[\"GarageYrBlt\"].ffill(inplace=True)\n",
    "null_Numerical.drop(columns=\"GarageYrBlt\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a712b1-1d02-424b-a977-0ec16c2e6548",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in null_Numerical.columns:\n",
    "    print(\"*\"*25+\"_\"+i+\"_\"+\"*\"*25)\n",
    "    print(f'skewness is  {df_housePrice[i].skew():.2f}')\n",
    "    print(f'kurtosis is {df_housePrice[i].kurtosis():.2f}')\n",
    "print(\"*\"*65)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693c8b6f-a910-46a2-9647-1f00f645bc80",
   "metadata": {},
   "source": [
    "A kurtosis value significantly greater than 3 (which is the kurtosis of a normal distribution) suggests that there are more extreme values (outliers) in the data, leading to a sharper peak and fatter tails. This means that the data may have a higher likelihood of producing values far from the mean.\n",
    "it can be clearly observe that <br><br> __[\" LotFrontage : 17.45\", \" MasVnrArea : 10.08 \" ]__ <br> Which is significantly greater than 3\n",
    "The distribution of this data is positively skewed. This means that the majority of the data points are concentrated on the left side of the distribution, with a longer tail extending to the right.<br>\n",
    "## __Therefore, it can be concluded that the median serves as a more suitable metric for imputation.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b375daaa-eebf-40c4-bd40-fa2f74e366e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in null_Numerical.columns:\n",
    "    df_housePrice[i].fillna(df_housePrice[i].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ad4efc-1eb1-4f2a-8656-356aebec4669",
   "metadata": {},
   "outputs": [],
   "source": [
    "del null_Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eadb54-953a-4e0e-9950-7a8d70f97f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_on()\n",
    "df_housePrice.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2131242-afc2-42de-b1be-f7f67205b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce68210-13f3-41cf-86b7-589a06d1e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housePrice.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab77eaa1-ce22-42fb-81cc-d2f900131b05",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Next_Day<br>\n",
    ">> Exploratory Data Analysis<br> \n",
    ">> Distribution of Numerical Variables<br>\n",
    ">> Distribution of Categorical Features<br>\n",
    ">> Distribution of Numerical Features with Sales Price<br>\n",
    ">> Correlation between Variables<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1435cbcd-a087-4ac7-a869-b9fc3c6f3803",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df85d505-a0c5-4d7a-bd11-ce8b438007f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_next=df_housePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18152de-9a69-47b2-94cf-34cdde395ac2",
   "metadata": {},
   "source": [
    "## Spliting columns into Numerical and Categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a1fab3-9e19-47f1-baed-8e0ebd2f8f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col=df_next.select_dtypes(include=['number'])\n",
    "cat_col=df_next.select_dtypes(include='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381cc811-bed1-4115-bfb6-422a40d83daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(f\"# Categorical have {len(cat_col.columns)} \\n # Numerical have {len(num_col.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5349c2e-424a-4139-af09-91e108639650",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a8493b-e854-4004-b8ac-a5b59bb6c6be",
   "metadata": {},
   "source": [
    "## Some columns are exhibiting significantly low standard deviation. This may indicate that there are categorical entries represented in numerical form. Therefore, we should address this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fe9a95-cbe9-4e7a-a446-70b96ec3175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LowStd=[]\n",
    "threshold=20\n",
    "for i in num_col.columns:\n",
    "    if threshold>num_col[i].std():\n",
    "        LowStd.append(i)\n",
    "for i in LowStd:\n",
    "    print(f\"The unique values for {i} are:- \\n {np.sort(num_col[i].unique())} with mode {num_col[i].mode()[0]} \\n\")\n",
    "Markdown(f\"## We have {len(LowStd)} Columns of Ordinal category in Numerical format\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5899685b-a475-4f09-9b30-c99131b81646",
   "metadata": {},
   "source": [
    "# The \"YrSold\" column is a temporal variable containing year values. Therefore, Encoding it with categorical data is not advisable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fad3f0-e2f1-42d2-bc9d-8617a7d14b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "LowStd.remove(\"YrSold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2edb80-4edb-40f8-9080-10dddc12957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col=pd.concat([cat_col, num_col[LowStd]],ignore_index=False,axis=1)\n",
    "\n",
    "num_col.drop(columns=num_col[LowStd],axis=1,inplace=True)\n",
    "del LowStd\n",
    "del threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e05a18-ef1a-4591-8025-c7c9e968ef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(f\"## Categorical have {len(cat_col.columns)} \\n ## Numerical have {len(num_col.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d13ee2c-da43-4a3b-9509-46b0eced54bb",
   "metadata": {},
   "source": [
    "## Numerical Analysis with Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181d783f-2f3c-444f-b649-a9e014ea9268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSize(rowSize,columnSize):\n",
    "    return (math.ceil(columnSize/rowSize),rowSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7a6b2b-a8be-499e-8c5a-85762dff8f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ ,cold=num_col.shape\n",
    "plt.figure(figsize=(10,cold)) \n",
    "\n",
    "pltSize=plotSize(3,cold)\n",
    "\n",
    "for i, column in enumerate(num_col):\n",
    "    plt.subplot(pltSize[0],pltSize[1],i+1)\n",
    "    sns.histplot(data=num_col, x=column, kde=True,bins=20,color='green')\n",
    "    \n",
    "    # plt.axvline(x=num_col[tg].median(), color=\"green\", linestyle='--', linewidth=2)\n",
    "    plt.axvline(x=num_col[column].median(), color=\"red\", linestyle='--', linewidth=2)\n",
    "\n",
    "    desc=f'skewness is {df_next[column].skew():.2f} \\n kurtosis is {df_next[column].kurtosis():.2f}'\n",
    "    plt.title(f'Distribution of {column} \\n{desc}')\n",
    "    sns.despine()\n",
    "plt.tight_layout()  # Adjust subplots to fit into figure area.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed299c23-77e5-4221-80a1-443d8626463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ ,cold=num_col.shape\n",
    "plt.figure(figsize=(10,cold)) \n",
    "\n",
    "pltSize=plotSize(3,cold)\n",
    "for i, column in enumerate(num_col):\n",
    "    plt.subplot(pltSize[0],pltSize[1], i+1)\n",
    "    sns.distplot(x=num_col[column])\n",
    "    plt.axvline(x=num_col[column].median(), color=\"red\", linestyle='--', linewidth=2)\n",
    "    desc=f'skewness is {df_housePrice[column].skew():.2f} \\n kurtosis is {df_housePrice[column].kurtosis():.2f}'\n",
    "    plt.title(f'Distribution of {column} \\n{desc}')\n",
    "    sns.despine()\n",
    "\n",
    "plt.tight_layout()  # Adjust subplots to fit into figure area.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2df7efc-8ee2-45b4-9438-eb41d0676c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.violinplot(data=df_housePrice, x=\"SalePrice\", y=column, palette=['blue','green']) \n",
    "_ ,cold=num_col.shape\n",
    "plt.figure(figsize=(10,cold)) \n",
    "\n",
    "pltSize=plotSize(3,cold)\n",
    "\n",
    "plt.figure(figsize=(10,cold*2)) \n",
    "for i, column in enumerate(num_col):\n",
    "    plt.subplot(pltSize[0],pltSize[1], i+1)\n",
    "    sns.violinplot(data=df_housePrice, x=column) \n",
    "    # sns.histplot(data=num_col, x=column, kde=True,bins=20,color='green')\n",
    "    desc=f'skewness is {df_housePrice[column].skew():.2f} \\n kurtosis is {df_housePrice[column].kurtosis():.2f}'\n",
    "    plt.title(f'Distribution of {column} \\n\\n{desc}')\n",
    "    sns.despine()\n",
    "\n",
    "plt.tight_layout()  # Adjust subplots to fit into figure area.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a709a3-939e-45ff-aed8-7ef97aa65742",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ ,cold=num_col.shape\n",
    "plt.figure(figsize=(10,cold)) \n",
    "\n",
    "pltSize=plotSize(3,cold)\n",
    " \n",
    "for i, column in enumerate(num_col):\n",
    "    plt.subplot(pltSize[0],pltSize[1], i+1)\n",
    "    sns.boxplot(data=df_next,x=column)\n",
    "    # sns.histplot(data=num_col, x=column, kde=True,bins=20,color='green')\n",
    "    desc=f'skewness is {df_housePrice[column].skew():.2f} \\n kurtosis is {df_housePrice[column].kurtosis():.2f}'\n",
    "    plt.title(f'Distribution of {column} \\n\\n{desc}')\n",
    "    sns.despine()\n",
    "\n",
    "plt.tight_layout()  # Adjust subplots to fit into figure area.\n",
    "plt.show()\n",
    "Markdown(f\"## Outliers can be identified as the points that fall outside box.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725068a9-5458-4b21-971e-26ed762ca6fe",
   "metadata": {},
   "source": [
    "## Distribution of Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19152f00-feb3-416c-8b48-36d74606a405",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ ,cold=cat_col.shape\n",
    "plt.figure(figsize=(10,cold*2)) \n",
    "for i, column in enumerate(cat_col):\n",
    "    plt.subplot(26,2, i+1)\n",
    "    sns.countplot(data=df_next, x=column)\n",
    "    plt.title(f'Distribution of {column} \\n Mode {df_next[column].mode()[0]}')\n",
    "    sns.despine()\n",
    "\n",
    "plt.tight_layout()  # Adjust subplots to fit into figure area.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77a7a62-441d-45d2-8ab9-02c01daf5477",
   "metadata": {},
   "source": [
    "## Numerical Relationship with Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fd0a10-585e-4902-900b-a0c13e6e4ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ ,cold=num_col.shape\n",
    "plt.figure(figsize=(10,cold)) \n",
    "\n",
    "pltSize=plotSize(3,cold)\n",
    "num_corr=num_col.corrwith(df_next['SalePrice'], axis=0, method='pearson')\n",
    "plt.figure(figsize=(10,cold)) \n",
    "for i, column in enumerate(num_col):\n",
    "    plt.subplot(pltSize[0],pltSize[1], i+1)\n",
    "    sns.regplot(data=df_next, x=column, y=df_next['SalePrice'])\n",
    "    plt.title(f\"{column}\\ncorrelation with Target {num_corr[column]:.3f}\")\n",
    "    sns.despine()\n",
    "\n",
    "plt.tight_layout()  # Adjust subplots to fit into figure area.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251253d2-c995-41f2-b238-2285d351b178",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(num_col.corr(), fmt=\".2f\", annot=True, cmap=\"coolwarm\", linewidths=0.5, linecolor=\"gray\")\n",
    "\n",
    "plt.title(\"headmap\", fontsize=8)\n",
    "\n",
    "# Show the heatmap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a57092-0e0f-48d4-b5ce-d889a0a36357",
   "metadata": {},
   "source": [
    "# Next_Day Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9261b7ea-3d9e-4831-a627-3345953ab6f9",
   "metadata": {},
   "source": [
    "## Encoding and translation numerical and categorical values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd80d05-b3eb-43a1-8558-da16143887d8",
   "metadata": {},
   "source": [
    "## Address the Object Type  of columns<br>\n",
    "## In a Categorical coulumn we have Ordinal Numerical and Object datatype<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31379f77-8b63-42c1-9a4c-60e80f5c90ba",
   "metadata": {},
   "source": [
    "## Trim the Categorical unique values in a prominent size of count\n",
    "## Less count unique values is termed as \"others\" followed by there column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e402e3-281e-4217-bb07-6627c293cd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting object data type only\n",
    "obj_col=cat_col.select_dtypes(include=\"O\")\n",
    "\n",
    "for i in obj_col.columns:\n",
    "    lowValue_counts = df_next[i].value_counts(normalize=True)\n",
    "    lowValue_counts = lowValue_counts[lowValue_counts < 0.05].index\n",
    "    df_next[i]= cat_col[i].apply(lambda x: 'Others_'+i if x in lowValue_counts else x)\n",
    "    \n",
    "for i in obj_col.columns:\n",
    "    print(f'{df_next[i].value_counts(normalize=True) * 100}\\n') \n",
    "Markdown(f\"### Significantly, low occurrence entries are categorised as others_with_There_respective column names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eb7c1b-7ab7-4303-a514-84f8ddd2902a",
   "metadata": {},
   "source": [
    "## Encoding of Categorical Data <br>\n",
    "### By grouping each entries of categorical colume with the target(mean, madian,sum,variance and Standard Deviation)<br>\n",
    ">> The objective is to determine the appropriate encoding method from among the available options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaa7172-b24b-45f3-8458-3fa1bb2db767",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ ,cold=obj_col.shape\n",
    "plt.figure(figsize=(10,cold*2)) \n",
    "\n",
    "pltSize=plotSize(2,cold)\n",
    "\n",
    "for i, column in enumerate(obj_col):\n",
    "    category_means = df_next.groupby(df_next[column])[tg].mean()\n",
    "    plt.subplot(pltSize[0],pltSize[1], i+1)\n",
    "    sns.barplot(x=category_means.index, y=category_means.values, palette='viridis')\n",
    "    plt.title(f'{column} vs {tg} mean', fontsize=16)\n",
    "    plt.xlabel(column, fontsize=14)\n",
    "    plt.ylabel(tg, fontsize=14)\n",
    "    sns.despine()\n",
    "plt.tight_layout()  # Adjust subplots to fit into figure area.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13142c66-d007-4f31-b8ba-acdcd8e9c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_ ,cold=obj_col.shape\n",
    "plt.figure(figsize=(10,cold*2)) \n",
    "\n",
    "pltSize=plotSize(2,cold)\n",
    "for i, column in enumerate(obj_col):\n",
    "    category_median = df_next.groupby(df_next[column])[tg].median()\n",
    "    plt.subplot(pltSize[0],pltSize[1], i+1)\n",
    "    sns.barplot(x=category_median.index, y=category_median.values, palette='viridis')\n",
    "    plt.title(f'{column} vs {tg} median', fontsize=16)\n",
    "    plt.xlabel(column, fontsize=14)\n",
    "    plt.ylabel(tg, fontsize=14)\n",
    "    sns.despine()\n",
    "plt.tight_layout()  # Adjust subplots to fit into figure area.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3c2a13-aad6-4d2e-bbe8-dfabf0c39e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_ ,cold=obj_col.shape\n",
    "plt.figure(figsize=(10,cold*2)) \n",
    "\n",
    "pltSize=plotSize(2,cold)\n",
    "for i, column in enumerate(obj_col):\n",
    "    category_sum = df_next.groupby(df_next[column])[tg].sum()\n",
    "    plt.subplot(pltSize[0],pltSize[1], i+1)\n",
    "    sns.barplot(x=category_sum.index, y=category_sum.values, palette='viridis')\n",
    "    plt.title(f'{column} vs {tg} sum', fontsize=16)\n",
    "    plt.xlabel(column, fontsize=14)\n",
    "    plt.ylabel(tg, fontsize=14)\n",
    "    sns.despine()\n",
    "plt.tight_layout()  # Adjust subplots to fit into figure area.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5adae2b-2fef-4284-8ecc-73dfd4207e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_ ,cold=obj_col.shape\n",
    "plt.figure(figsize=(10,cold*2)) \n",
    "\n",
    "pltSize=plotSize(2,cold)\n",
    "for i, column in enumerate(obj_col):\n",
    "    category_var = df_next.groupby(df_next[column])[tg].var()\n",
    "    plt.subplot(pltSize[0],pltSize[1], i+1)\n",
    "    sns.barplot(x=category_var.index, y=category_var.values, palette='viridis')\n",
    "    plt.title(f'{column} vs {tg} Variance', fontsize=16)\n",
    "    plt.xlabel(column, fontsize=14)\n",
    "    plt.ylabel(tg, fontsize=14)\n",
    "    sns.despine()\n",
    "plt.tight_layout()  # Adjust subplots to fit into figure area.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0f595c-47f3-4fec-a7d3-2a56432629ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_ ,cold=obj_col.shape\n",
    "plt.figure(figsize=(10,cold*2)) \n",
    "\n",
    "pltSize=plotSize(2,cold)\n",
    "for i, column in enumerate(obj_col):\n",
    "    category_std = df_next.groupby(df_next[column])[tg].std()\n",
    "    plt.subplot(pltSize[0],pltSize[1], i+1)\n",
    "    sns.barplot(x=category_std.index, y=category_std.values, palette='viridis')\n",
    "    plt.title(f'{column} vs {tg} SD', fontsize=16)\n",
    "    plt.xlabel(column, fontsize=14)\n",
    "    plt.ylabel(tg, fontsize=14)\n",
    "    sns.despine()\n",
    "plt.tight_layout()  # Adjust subplots to fit into figure area.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b774dd63-1869-4ac9-b9f8-0fa03cb6cfaa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## I have ultimately chosen to implement Standard Deviation Encoding to ensure that the assigned rank remains stable despite fluctuations in sales prices.\n",
    "\n",
    "#### __ Why Standard deviation ?__\n",
    ">> It will show very low variation on New entries of Sales Price hance the Encoded Rank will intaked<br>\n",
    ">> It consist of Variance so help in learning<br>\n",
    ">> It is a standardised by square root Hence, more stable<br>\n",
    ">> Because of CTL and Large Number Theorem, This encoding is done before split<br>\n",
    ">> And through ranking, we can prevent the Data Leak<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c47f82-8da8-4d98-b264-e5894e463093",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Q Why not others:\n",
    ">>__Sum__:The rnaking may can change by updating values on Sales Price which cause Misinterpretation on encoding<br>\n",
    ">>__Mean__: The rnaking may can change by updating values on Sales Price which cause Misinterpretation on encoding and also Sensitive with outliers<br>\n",
    ">>__Median__: The rnaking may can change by updating values on Sales Price <br>\n",
    ">>__variance__: Variance is an essential component of the learning process; however,<br>\n",
    ">> it also results in an increase in dimensionality due to the squaring of values.<br>\n",
    ">>Nevertheless, this effect remains consistent regardless of new data entries.\n",
    ">>Just Careful with null values it will. Block you to encode the rank for this .fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98bede4-af44-411b-99d0-4f7bccd6bce5",
   "metadata": {},
   "source": [
    "## Q How to data with data leak\n",
    ">>The ranking mechanism employed here enables us to obscure the true standard variation among categories; consequently, the issue of data leakage has been effectively addressed. And the string categorical value becomes ordinal categorical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee62b070-ac11-4886-85d2-5918a3ad67da",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is a key dictionary for input control while developing web application For those category values\n",
    "'''\n",
    "cat_key_dictonary={}\n",
    "\n",
    "for i in obj_col.columns:\n",
    "    cat_key_dictonary[i]=None\n",
    "    \n",
    "    _encoded= df_next.groupby(cat_col[i])[tg].std().fillna(0)  # Calculate mean Sales for each Category\n",
    "    _encoded = _encoded.rank(method='dense').astype(int)\n",
    "    \n",
    "    cat_key_dictonary[i]=dict(zip(_encoded.index.tolist(),_encoded.values.tolist()))\n",
    "    \n",
    "    cat_col[i] = cat_col[i].map(_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5283d28-1249-41a8-9d9a-8cb13ef382fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_key_dictonary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87a39de-cbb8-4a4c-86b8-d8705d1ac433",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cat_col.corr(), fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5, linecolor=\"gray\")\n",
    "plt.title(\"headmap\", fontsize=8)\n",
    "\n",
    "# Show the heatmap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42317d6-39d2-4781-b96a-60de8926042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ ,cold=cat_col[obj_col.columns].shape\n",
    "plt.figure(figsize=(10,cold*2)) \n",
    "\n",
    "pltSize=plotSize(2,cold)\n",
    "num_corr=cat_col[obj_col.columns].corrwith(df_next['SalePrice'], axis=0, method='pearson')\n",
    "plt.figure(figsize=(10,cold)) \n",
    "for i, column in enumerate(cat_col[obj_col.columns]):\n",
    "    plt.subplot(pltSize[0],pltSize[1], i+1)\n",
    "    sns.regplot(data=cat_col, x=column, y=df_next['SalePrice'])\n",
    "    plt.title(f\"{column}\\ncorrelation with Target {num_corr[column]:.3f}\")\n",
    "    sns.despine()\n",
    "\n",
    "plt.tight_layout()  # Adjust subplots to fit into figure area.\n",
    "plt.show()\n",
    "del num_corr\n",
    "Markdown(f\"## The graph demonstrates that the integrity of Categorical information is preserved within a numerical framework, while also maintaining the dimensional aspect. \")             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3f6482-3edc-47b7-9160-a6acc9b8ee9a",
   "metadata": {},
   "source": [
    "## Final Categorical Assingment to main Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a442d9d2-ee99-4b0d-b760-1da68a69312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_on()\n",
    "df_housePrice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0987d7-20f0-4a66-874f-fb2c46b31717",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housePrice[cat_col.columns]=cat_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37f2e46-ab5e-4df0-8982-f42f18b212e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del cold\n",
    "del obj_col\n",
    "del cat_col\n",
    "del num_col\n",
    "del df_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceda13f0-f2dc-4434-9a5c-f61e2fdad1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc57a822-0157-41ca-9f03-ea589506c3ce",
   "metadata": {},
   "source": [
    "# Model Selection and Predicting The Standard Evaluation Score will R2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4569899-77d5-41f8-bc5d-2352180e6904",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_housePrice['SalePrice']\n",
    "x = df_housePrice.drop(\"SalePrice\",axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be8d4b6-8cef-4bb7-8860-38cf10e27d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.30,random_state=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a38fd3-3fd4-45b4-a050-b1c4533515a7",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4ec1c6-f9e4-4208-acb2-8b8956429c6e",
   "metadata": {},
   "source": [
    "__ Outlier Detection: __<br>\n",
    ">>  IQR Method: Detects outliers based on values lying outside [Q1 - 1.5*IQR, Q3 + 1.5*IQR].<br>\n",
    ">> Z-score Method: Detects outliers where the z-score is greater than 3 or less than -3.<br>\n",
    "\n",
    "__ Imputation Strategy:__ <br>\n",
    "\n",
    ">> Mean: Replaces outliers with the mean of non-outlier values.<br>\n",
    ">> Median: Replaces outliers with the median of non-outlier values (robust against skewed data).<br>\n",
    ">> Mode: Replaces outliers with the mode (most frequent value)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaecd9c-a17f-4037-ad7c-b5beb3da4506",
   "metadata": {},
   "source": [
    "### With reference of normal distribution<br>\n",
    ">>The __Kurtosis__ of a normal distribution is 3<br>\n",
    ">>The __Skewness of__ a normal distribution is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8c2efa-5eff-41d2-9c16-23ccd02cbd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e565a2fd-3637-4f55-bb09-789bd879f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Data frame for outliers\n",
    "Outlier_numerical_columns = x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492f5367-b861-4354-be3b-bbb6f51c5efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" \n",
    "Iterate column wise for IQR and zscore \n",
    "winsorize has its own Iterator \n",
    "Default Parameters:\n",
    "method='IQR' \n",
    "impute_strategy='median'\n",
    "\"\"\"\n",
    "# CheckPoint make sure to donot disturbe the approximate normal columns only deal with high skew and kurtosis columns \n",
    "def checkPoint(df,i='_'):\n",
    "    t=True\n",
    "    stdcheck = lambda: df[i].std() < 2\n",
    "    kurcheck = lambda: 0 < df[i].kurtosis() < 3\n",
    "    skecheck = lambda: 0 < df[i].skew() < 2 \n",
    "    if stdcheck():\n",
    "        #skipd in range\n",
    "        t=False\n",
    "    elif kurcheck():\n",
    "        t=False\n",
    "    elif skecheck():\n",
    "        t=False\n",
    "    return t\n",
    "# Experimant with Outliers and Evaluate on the basis of std,skew and kurtosis\n",
    "def SKEvaluateData(df):\n",
    "    t=True\n",
    "    for i in df:\n",
    "        '''\n",
    "            The Kurtosis of a normal distribution is 3\n",
    "            The Skewness of a normal distribution is 0\n",
    "            And Having more then 2 Standard Deviation\n",
    "        \n",
    "        '''\n",
    "        if checkPoint(df,i):\n",
    "            t=False\n",
    "            print(\"*\"*25+\"_\"+i+\"_\"+\"*\"*25)\n",
    "            print(f'skewness is  {df[i].skew():.2f}')\n",
    "            print(f'kurtosis is {df[i].kurtosis():.2f}')\n",
    "            print(f'S___T__D is {df[i].std():.2f}')\n",
    "            print(\"*\"*65)\n",
    "    if t :\n",
    "        print(\"Good!üü¢ to Go Everything is Normal\")\n",
    "    else:\n",
    "        print(\"\"\"There are certain columns in the data set that contain outlier values. \\n \n",
    "        It is acceptable to encounter outliers on occasion \\n don't be Greedy üòè\"\"\")\n",
    "        \n",
    "def detect_and_impute_outliers(df, column='_', method='winsorize', impute_strategy='median'):\n",
    "    \n",
    "    if method =='winsorize':\n",
    "        from scipy.stats import mstats\n",
    "        for col in df:\n",
    "            if checkPoint(df,col):\n",
    "                df[col] = mstats.winsorize(df[col], limits=[0.1, 0.1])\n",
    "        return df\n",
    "        \n",
    "    if method == 'IQR':\n",
    "        # IQR Method\n",
    "        Q1 = df[column].quantile(0.25)  # First quartile\n",
    "        Q3 = df[column].quantile(0.75)  # Third quartile\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Detect outliers\n",
    "        outliers = (df[column] < lower_bound) | (df[column] > upper_bound)\n",
    "    \n",
    "    elif method == 'zscore':\n",
    "        # Z-score Method\n",
    "        mean = df[column].mean()\n",
    "        std = df[column].std()\n",
    "        z_scores = (df[column] - mean) / std\n",
    "        outliers = (z_scores.abs() > 3)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Invalid method. Choose 'IQR' ,'zscore' or 'winsorize'.\")\n",
    "\n",
    "    print(f\"Detected outliers:\\n{df[outliers]}\")\n",
    "\n",
    "    # Impute outliers\n",
    "    if impute_strategy == 'mean':\n",
    "        replacement_value = df[~outliers][column].mean()\n",
    "    elif impute_strategy == 'median':\n",
    "        replacement_value = df[~outliers][column].median()\n",
    "    elif impute_strategy == 'mode':\n",
    "        replacement_value = df[~outliers][column].mode()[0]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid impute strategy. Choose 'mean', 'median', or 'mode'.\")\n",
    "\n",
    "    df.loc[outliers, column] = replacement_value\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a19a17c-6597-4268-b5b6-d47d168126ff",
   "metadata": {},
   "source": [
    "### Experiment Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e0004c-1976-44de-92cc-88cf0ee50c3d",
   "metadata": {},
   "source": [
    "## Befor Outlier Treatement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf5e826-c92b-45c2-aad9-3a20dca4dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "SKEvaluateData(Outlier_numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157c7a96-11c5-43e1-983c-a9df946ec933",
   "metadata": {},
   "source": [
    "### Outlier in Zscore with median imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff7342-4f3c-4691-bae4-aae18b513977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in Outlier_numerical_columns:\n",
    "#      if checkPoint(Outlier_numerical_columns,i):\n",
    "#         Outlier_numerical_columns=detect_and_impute_outliers(Outlier_numerical_columns,i, method='zscore', impute_strategy='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beaf988-990e-4c98-a57d-0c3cefce67d4",
   "metadata": {},
   "source": [
    "### Winsorize by 0.1% both the side "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a19f80-838f-4eb5-8c41-7818a449f54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier_numerical_columns=detect_and_impute_outliers(Outlier_numerical_columns, method='winsorize')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8957db57-e83b-49ae-b0a6-a8f86a3ecd3a",
   "metadata": {},
   "source": [
    "### Outlier in IQR with median imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689b07da-00c6-4bf0-a053-f1fa8f7ff16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Outlier_numerical_columns:\n",
    "    if checkPoint(Outlier_numerical_columns,i):\n",
    "        Outlier_numerical_columns=detect_and_impute_outliers(Outlier_numerical_columns,i, method='IQR', impute_strategy='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6a1e7b-73a8-4f2c-a633-ad88485dc7f0",
   "metadata": {},
   "source": [
    "## After Outlier Treatement\n",
    ">> find a message to go green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0daa85-ca32-4754-a3bd-674b905a9136",
   "metadata": {},
   "outputs": [],
   "source": [
    "SKEvaluateData(Outlier_numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780f238b-5972-4633-8fd7-a45e1d9bd49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[Outlier_numerical_columns.columns]=Outlier_numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b971aff3-d38e-45fe-9b3f-9335335e150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Profile=ProfileReport(x_train,title=\" Independent_Data_without_Outliers_Analysis\",explorative=True)\n",
    "\n",
    "Profile.to_notebook_iframe()\n",
    "\n",
    "\n",
    "Profile.to_file(\"Independent_Data_without_Outliers_Analysis.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964e204c-928d-46f2-93be-6667c3e8ac8e",
   "metadata": {},
   "source": [
    "# Normalization and scaling\n",
    ">> __When to Normalize?__<br>\n",
    "When features have different scales (e.g., one is in kilometers, another in meters).<br>\n",
    "When required by the algorithm (e.g., SVM, k-NN, PCA).<br>\n",
    ">__Which Method to Choose?__<br>\n",
    "Use Min-Max Normalization for bounded data like pixel values. [0,1] <br>\n",
    "Use Z-score Normalization for unbounded data or models sensitive to feature scaling.[-3,3]<br>\n",
    "Use Robust Scaling if your dataset contains many outliers.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac97b32a-7674-4962-818a-9a2f58bc79ed",
   "metadata": {},
   "source": [
    "## Options for Scaling  Min-Max Scaler , StandardScaler And RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b5f94a-8909-4a1f-bf12-19de110767bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NS_numerical_columns = x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81debcce-aa70-4970-81cb-be1104403205",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Select from the list with correct speling\n",
    "   [ Min-Max Scaler , StandardScaler , RobustScaler]\n",
    "   return type is  pandas dataframe \n",
    "\"\"\"\n",
    "def NormalizationMethod(df,method='_'):\n",
    "    if method == 'min_maxScaler':\n",
    "        \n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        scaler = MinMaxScaler()\n",
    "        normalized_data = scaler.fit_transform(df)\n",
    "        return pd.DataFrame(normalized_data, columns=df.columns)\n",
    "    elif method == 'StandardScaler':\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        standardized_data = scaler.fit_transform(df)\n",
    "        return pd.DataFrame(standardized_data, columns=df.columns)\n",
    "    elif method == 'RobustScaler':\n",
    "        from sklearn.preprocessing import RobustScaler\n",
    "        scaler = RobustScaler()\n",
    "        robust_scaled_data = scaler.fit_transform(df)\n",
    "        return pd.DataFrame(robust_scaled_data, columns=df.columns)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method. Choose Min-Max Scaler , StandardScaler , RobustScaler.\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e056958-d1e6-426c-9e7f-d0fc862f2109",
   "metadata": {},
   "source": [
    "## Please select any one option; that will sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75847b11-5e3c-4e51-b040-9d40e76034c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NS_numerical_columns=NormalizationMethod(NS_numerical_columns,method='RobustScaler') \n",
    "# select any one from hear:- Min-Max Scaler , StandardScaler , RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048bc1d6-40af-4567-8d37-07563c641286",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[NS_numerical_columns.columns]=NS_numerical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0dd747-e198-4e68-a659-f5b0789153c0",
   "metadata": {},
   "source": [
    "## Regression models library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c87877-e1a2-4a64-9891-744aaa14f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Evaluation and test score \n",
    "from sklearn.metrics import mean_squared_error,r2_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67570ccd-8be5-4816-b437-358d606d2ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model dictionary\n",
    "models = {\n",
    "    'LinearRegression':LinearRegression(),\n",
    "    'RandomForestRegressor':RandomForestRegressor(),\n",
    "    'XGBRegressor':XGBRegressor(),\n",
    "    # 'SGDRegressor':SGDRegressor(),\n",
    "    # 'SVR':SVR(),\n",
    "    'Ridge':Ridge(),\n",
    "    'ElasticNet':ElasticNet(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a13c3f-9e9c-455f-a12a-00c8c0348d9f",
   "metadata": {},
   "source": [
    "## Causion <br>\n",
    ">> ElasticNet,Redige,Linear Regression and  Others can cause change in input with Null values and this change may can effect all the instance<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60491b74-4aa4-49ed-90ad-bb9831d31d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_results_R2 = []\n",
    "model_results_RMSE = []\n",
    "model_names = []\n",
    "\n",
    "\"\"\"\n",
    "ElasticNet,Redige,Linear Regression and  \n",
    "Others can cause change in input entries to  Null values and this change may can effect all the instance\n",
    "step1>> Go to main split test train cell \n",
    "step2>> Run All befor model dictionary cell\n",
    "step3>> Select one Model at a time and run slowly\n",
    "\"\"\"\n",
    "\n",
    "# training the model with function\n",
    "for name,model in models.items():\n",
    "    a = model.fit(x_train,y_train)\n",
    "    predicted = a.predict(x_test)\n",
    "    scoreRMSE = np.sqrt(mean_squared_error(y_test, predicted))\n",
    "    scoreR2 = r2_score(y_test, predicted) \n",
    "    model_results_RMSE.append(scoreRMSE)\n",
    "    model_results_R2.append(scoreR2*100)\n",
    "    model_names.append(name)\n",
    "    \n",
    "    #creating dataframe\n",
    "    df_results = pd.DataFrame([model_names,model_results_RMSE,model_results_R2])\n",
    "    df_results = df_results.transpose()\n",
    "df_results = df_results.rename(columns={0:'Models',1:'RMSE',2:\"R2_Score\"}).sort_values(by='R2_Score',ascending=False,)\n",
    "    \n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8d314a-d9d0-4258-93bb-035a3e10cfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile=ProfileReport(x_train,title=\" Evaluation\",explorative=True)\n",
    "\n",
    "# Profile.to_notebook_iframe()\n",
    "\n",
    "\n",
    "# Profile.to_file(\"Model Evaluation Analysis.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee8e977-3007-4a4e-9aee-d8c521e028e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# End of  Modeling and Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04abd4ca-69c3-4010-8530-4b09f1db7fdf",
   "metadata": {},
   "source": [
    "# Challanges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ece3cfc-94d6-4e66-8605-2d12d5f98f3b",
   "metadata": {},
   "source": [
    ">> Dealing with Null values<br>\n",
    ">> Encoding null and also find the best way to not to increase dimentionality<br>\n",
    ">> Outliers Detection and imputation<br>\n",
    ">> Selecting the best Model for parameter<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b3edc2-1017-437f-a715-7d7520b70765",
   "metadata": {},
   "source": [
    "### Advance Improvement Future scope\n",
    ">> Proper handling with Null values<br>\n",
    ">> Creating a bin for Year based columns and ordinal imputation like {year 1998 to 2000 can be called as old or assinged with 0}<br>\n",
    ">> More Advance Paremetric selection with Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395f1e91-5088-47b7-979a-0d9ac265086d",
   "metadata": {},
   "source": [
    "## These are the suggested values for a Customer \tSalePrice $108000.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e91736-6a74-4903-93d5-4d704f1c7558",
   "metadata": {},
   "source": [
    "MSSubClass\tMSZoning\tLotFrontage\tLotArea\tStreet\tAlley\tLotShape\tLandContour\tUtilities\tLotConfig\tLandSlope\tNeighborhood\tCondition1\tCondition2\tBldgType\tHouseStyle\tOverallQual\tOverallCond\tYearBuilt\tYearRemodAdd\tRoofStyle\tRoofMatl\tExterior1st\tExterior2nd\tMasVnrType\tMasVnrArea\tExterQual\tExterCond\tFoundation\tBsmtQual\tBsmtCond\tBsmtExposure\tBsmtFinType1\tBsmtFinSF1\tBsmtFinType2\tBsmtFinSF2\tBsmtUnfSF\tTotalBsmtSF\tHeating\tHeatingQC\tCentralAir\tElectrical\t1stFlrSF\t2ndFlrSF\tLowQualFinSF\tGrLivArea\tBsmtFullBath\tBsmtHalfBath\tFullBath\tHalfBath\tBedroomAbvGr\tKitchenAbvGr\tKitchenQual\tTotRmsAbvGrd\tFunctional\tFireplaces\tFireplaceQu\tGarageType\tGarageYrBlt\tGarageFinish\tGarageCars\tGarageArea\tGarageQual\tGarageCond\tPavedDrive\tWoodDeckSF\tOpenPorchSF\tEnclosedPorch\t3SsnPorch\tScreenPorch\tPoolArea\tPoolQC\tFence\tMiscFeature\tMiscVal\tMoSold\tYrSold\tSaleType\tSaleCondition\tSalePrice\n",
    "403\t403\t30\tRL\t60\t10200\tPave\tNA\tReg\tLvl\tAllPub\tInside\tGtl\tSawyer\tNorm\tNorm\t1Fam\t1Story\t5\t8\t1940\t1997\tGable\tCompShg\tWd Sdng\tWd Sdng\tNone\t0\tTA\tTA\tPConc\tTA\tTA\tNo\tUnf\t0\tUnf\t0\t672\t672\tGasA\tEx\tY\tSBrkr\t672\t0\t0\t672\t0\t0\t1\t0\t2\t1\tTA\t4\tTyp\t0\tNA\tDetchd\t1940\tUnf\t1\t240\tTA\tTA\tN\t168\t0\t0\t0\t0\t0\tNA\tGdPrv\tNA\t0\t8\t2008\tWD\tNormal\t108000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b7bbc9-42b3-4500-a0ea-57247d45c362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
